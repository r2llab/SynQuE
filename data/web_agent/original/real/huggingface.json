{
  "Huggingface--0": "Find a pre-trained natural language processing model on Hugging Face that can perform sentiment analysis, and make sure the model's last update is within March 2023.",
  "Huggingface--1": "Use the Huggingface Inference API to generate a short story about a dragon and a wizard.",
  "Huggingface--2": "Discover three new and popular open-source NLP models for language translation released in the past month on Huggingface.",
  "Huggingface--3": "Look up a model with a license of cc-by-sa-4.0 with the most likes on Hugging face.",
  "Huggingface--4": "Locate an open-source conversational AI model on Hugging Face, trained in English and list its main features and applications.",
  "Huggingface--5": "Find a model released on Hugging Face for recipe generation. Retrieve the information of the model, including its name, model size and tensor type.",
  "Huggingface--6": "Find the model sentence-transformers/all-MiniLM-L6-v2 and use the Inference API on the webpage to get the similarity of the following two sentences: 'Tomorrow is Sunday', 'Eat a burger on Sunday'.",
  "Huggingface--7": "Which is the most downloaded audio related dataset on Hugging face currently.",
  "Huggingface--8": "Retrieve an example of a pre-trained language model in natural language processing and identify the tasks it is specifically designed for, like translation or text summarization.",
  "Huggingface--9": "Find the most download machine translation model on Huggingface which focuses on English and Japanese (en-ja) and report the evaluation metrics stated for it.",
  "Huggingface--10": "Open space: argilla/notux-chat-ui and interact with it by asking it 'which team trained you'. What is its answer.",
  "Huggingface--11": "Identify the latest updated image to video model available on Huggingface and summarize its main features.",
  "Huggingface--12": "Find the most recently updated machine learning model on Huggingface which focuses on Error Correction.",
  "Huggingface--13": "Search for LLaMA in the huggingface doc, what type is the spaces_between_special_tokens parameter in LlamaTokenizer and what is its default value.",
  "Huggingface--14": "How much is the Pro account of Hugging face for a month and what are the features?",
  "Huggingface--15": "Identify the most downloaded models on Hugging face that use the PaddlePaddle library.",
  "Huggingface--16": "Find information on the latest (as of today's date) pre-trained language model on Huggingface suitable for text classification and briefly describe its intended use case and architecture.",
  "Huggingface--17": "Find the most recently updated open-source project related to natural language processing on the Huggingface platform. Provide the project's name, creator, and a brief description of its functionality.",
  "Huggingface--18": "Look up TRL's forward modelling in the hugging face documentation on how to add a margin to a loss.",
  "Huggingface--19": "Explore and summarize the features of the most recent open-source NLP model released by Hugging Face for English text summarization.",
  "Huggingface--20": "Locate a pre-trained natural language processing model on Hugging Face that specializes in named entity recognition (NER), confirm that the model was last updated in 2022 and has 1M+ downloads.",
  "Huggingface--21": "Look up the tour about how to use the 'pipeline' feature in the Hugging Face Transformers library for sentiment analysis, and identify the default model it uses.",
  "Huggingface--22": "Identify the steps to convert a PyTorch model to TensorFlow using the Hugging Face Transformers library as described in their documentation.",
  "Huggingface--23": "Identify three innovative and widely recognized open-source NLP models for automatic speech recognition released in the past month on Huggingface.",
  "Huggingface--24": "Search for a model on Hugging Face with an Apache-2.0 license that has received the highest number of likes.",
  "Huggingface--25": "In the Hugging Face documentation, find the tutorial on loading adapters with PEFT, tell me how to load in 8bit or 4bit.",
  "Huggingface--26": "Identify a model on Hugging Face designed for generating travel chats. Obtain information about the model, including its name, size and training framwork.",
  "Huggingface--27": "Determine the most downloaded dataset related to Text Retrieval in NLP on Hugging Face.",
  "Huggingface--28": "Retrieve an example of a pre-trained model on Hugging Face that is optimized for question answering tasks and detail the languages it supports.",
  "Huggingface--29": "Summarize the description of the recent open-source NLP model released on Hugging Face for medical summarization.",
  "Huggingface--30": "Identify the most downloaded English-Chinese (en-zh) machine translation model on Huggingface and report its latest performance metrics and usage guidelines.",
  "Huggingface--31": "Identify the latest machine learning model on Huggingface that specializes in detecting fake news, including the date of its last update.",
  "Huggingface--32": "On the Hugging Face website, search for the model 'GPT-J-6B' and find the 'temperature' parameter in its settings. What is the default value of this parameter?",
  "Huggingface--33": "List three hugging face docs. How many GitHub stars have they earned so far?",
  "Huggingface--34": "List the benefits of hugging face classroom mentioned on Hugging face website.",
  "Huggingface--35": "Find the latest Diffusion-related blog on Hugging Face, and read its intro or overview section to roughly summarize the content of the blog.",
  "Huggingface--36": "Summarize all the payment plans and their advantages in huggingface pricing.",
  "Huggingface--37": "Browse the daily paper on Hugging Face. What is the title of the first article, how many upvotes has it received, and is there any related model or data release?",
  "Huggingface--38": "Investigate the 'transformers' library in the Hugging Face documentation, focusing on how to add new tokens to a tokenizer.",
  "Huggingface--39": "Investigate in the Hugging Face documentation how to utilize the 'Trainer' API for training a model on a custom dataset, and note the configurable parameters of the Trainer class.",
  "Huggingface--40": "Check out Text Embeddings Inference in Hugging face's Doc to summarise the strengths of the toolkit.",
  "Huggingface--41": "What is the current Text-to-3D model with the highest number of downloads and tell me are there Spaces that use the model.",
  "Huggingface--42": "Check the Dataset Viewer for ai2lumos/lumos_complex_qa_plan_onetime on Hugging face. what is the content corresponding to user in the first message?"
}